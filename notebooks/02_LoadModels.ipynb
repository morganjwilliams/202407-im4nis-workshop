{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [**Overview**](./00_overview.ipynb) | [**EDA**](./01_EDA.ipynb) | [**Using `sklearn` Models**](./02_UsingModels.ipynb) |\n",
    "| -- | -- | -- |\n",
    "\n",
    "# Loading and Using Existing `sklearn` to Make Predictions\n",
    "\n",
    "In this notebook we'll:\n",
    "* Upload some serialized models which have already been trained to Jupyter Lab\n",
    "* Load these models into `sklearn` object using `joblib`\n",
    "* Use these models with appropriate data to make new predictions\n",
    "* Serialize these predictions for use elsewhere\n",
    "\n",
    "Note: If you haven't already, run the download notebook [here](../data/DownloadData.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When importing existing models, the key aspect for `sklearn` is that the versions in an ideal case would match; when you try to load models with an inconsistent version, you'll get a warning (in the best case) and may get an error. The model files for the IM4NiS project were built with `scikit-learn v1.1.3` (now a bit out of date); this was the default version installed in this environment (at least via Binder, or if you used the `environment.yml` file associated with this notebook). We can check the version of `sklearn` we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've verified we have the right version of `sklearn`, we can load up a file in `joblib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "clf = joblib.load( # this is a classifier file, hence i've named it clf here- you could call it whatever you like, as long as you're consistent\n",
    "    \"../data/MachineLearningModels/Spinel_LAICPMS_Binary_Mineralization_Classifier.joblib\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the classifier is a histogram-gradient-boosted classifier (a fancy form of random forest), and any of the parameters set on it's instantiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check what the features the clasisfier was trained on were, in case we didn't have the training dataset handy (in this case, we do, but it's stil good to check):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see what classes the classifier predicts, noting here we expect a binary mineralized/unmineralized class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note about this list of features is that they include some things which are not likely provided as standard in most datasets, so we might have to calculate them. This includes the lambdas and assocaited REE anomalies Eu/Eu* and Ce/Ce*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier exposes a `.predict()` method, which we'll use to classify our new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data, Introspection and Model Performance\n",
    "\n",
    "As the training and testing data is provided in DAP, you can independently conduct model introspection and performance evaluation in the same way we've done it during the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_model_data(name):\n",
    "    \"\"\"\n",
    "    Conveience function to do a quick lookup of data files by name,\n",
    "    and load the relevant items.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        p.stem.replace(name + \"_\", \"\"): (\n",
    "            pd.read_csv(p) if p.suffix == \".csv\" else joblib.load(p)\n",
    "        )\n",
    "        for p in Path(\"../data/MachineLearningModels\").rglob(\"{}*\".format(name))\n",
    "    }\n",
    "\n",
    "\n",
    "clf_data = get_model_data(\"Spinel_LAICPMS_Binary_Mineralization\")\n",
    "clf = clf_data['Classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_data['XX_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(clf_data['XX_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(clf_data['XX_test'], clf_data['yy_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifications on New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read the data\n",
    "* Transform into consistent units\n",
    "* Do any required geochemical transformation\n",
    "* Add any extra features (i.e., lambdas)\n",
    "* Drop any unrequired columns\n",
    "* *In cases where the model can't handle missing data*: Decide how to eliminate missing data - dropping rows, columns, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [**Overview**](./00_overview.ipynb) | [**EDA**](./01_EDA.ipynb) | [**Using `sklearn` Models**](./02_UsingModels.ipynb) |\n",
    "| -- | -- | -- |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "im4nis-workshop-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
