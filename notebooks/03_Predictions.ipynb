{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [**Overview**](./00_overview.ipynb) | [**From Data Exploration to Machine Learning**](./01_EDA.ipynb) | [**Using `sklearn` Models**](./02_LoadModels.ipynb) | [**Making Predictions**](./03_Predictions.ipynb)|\n",
    "| -- | -- | -- | -- |\n",
    "\n",
    "# Making Predictions: Classifying New Data\n",
    "\n",
    "In this notebook, we will:\n",
    "* Use IM4NiS models with appropriate data to make new predictions\n",
    "* Demonstrate how to use the training data to make new models\n",
    "* Plot our predictions on a map\n",
    "* Serialize these predictions for use elsewhere\n",
    "\n",
    "Note: If you haven't already, run the download notebook [here](../data/DownloadData.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrolite.geochem\n",
    "import pyrolite.plot\n",
    "\n",
    "from util import get_model_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load up the model data for the TIMA binary mineralization classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_data = get_model_data(\"Spinel_TIMA_Binary_Mineralization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, our Heavy Mineral Map of Australia Dataset, which includes geospatial information we'll use a bit later; first we'll check it exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Path(\n",
    "    \"../data/HMMA_Spinel_Locations_apfu.xlsx\"\n",
    ").exists(), \"Missing dataset - you might need to upload it to the 'data' folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/HMMA_Spinel_Locations_apfu.xlsx\").dropna(how=\"all\")\n",
    "gdf = gpd.GeoDataFrame(  # turn our dataframe into a geodataframe, which natively knows coordinates\n",
    "    df, geometry=gpd.points_from_xy(df[\"LONG_GDA94\"], df[\"LAT_GDA94\"]), crs=\"GDA94\"\n",
    ")\n",
    "# the TIMA data comes with unnecessary rows.. we can drop them!\n",
    "gdf = gdf.loc[~gdf.SampleID.isin([\"Average concentration\", \"Standard deviation\"])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In terms of what we'll need to do for a new dataset to line it up with our training dataset, it'll roughly include:\n",
    "* Read the data\n",
    "* Transform into consistent units\n",
    "* Do any required geochemical transformation\n",
    "* Add any extra features (i.e., lambdas)\n",
    "* Drop any unrequired columns\n",
    "* *In cases where the model can't handle missing data*: Decide how to eliminate missing data - dropping rows, columns, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have a model already made for TIMA compositions of spinel, *but*, the features it requires differ to those from the HMMA dataset (with contrast in representation as elements/oxides, and different elements measured):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pyrochem.list_oxides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which differs from what our classifer expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(clf_data[\"Classifier\"].feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this mismatch in data, we'll need to build a new model based on the common subset of geochemistry we have in both the training dataset and the prediction dataset. Luckily, we have everything we need already. We can figure out what overlap we have in terms of mineral chemistry; *note that `pyrolite` will spit out warnings for missing geochemical species*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_subset = (\n",
    "    df.pyrochem.convert_chemistry(to=clf_data[\"Classifier\"].feature_names_in_)\n",
    "    .pyrochem.elements.dropna(how=\"all\", axis=1)\n",
    "    .columns\n",
    ")\n",
    "common_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to define a new subset of data to train a new model on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clf_data[\"XX_train\"][common_subset]\n",
    "y_train = clf_data[\"yy_train\"].iloc[:, 0] # take just the first column, as this is a 1-column dataframe\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then train a simple random forest model, here with default parameterization (other than controlling the random seed, so everyone gets the same results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=17)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, the data comes in weight percent, which we'll need to convert to fractional compositions (summing to 1, rather than 100%) to compare to our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = gdf.pyrochem.convert_chemistry(to=common_subset).pyrochem.elements / 100\n",
    "X_predict.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some missing data in out prediction dataset, and in this instance we won't be making predictions for those analyses (to do so, we'd need to use a different model, or impute the values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltr = ~pd.isna(X_predict).any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now filter our datset, and make predictions on analyses which don't have missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[fltr, \"Prediction\"] = clf.predict(X_predict[fltr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And have a look at the relative proportion of predictions (notably, mostly unmineralized, which is probably to be expected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[fltr, \"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at predictions on a grain-by-grain basis provides lots of information, we typically want to look at the data at a sample-by-sample basis (or, potentially coarser). So here what we'll do is aggregate our predictions by sample, and extract both the proportions of grains which are predicted to be from mineralized hosts and the overall number of predictions made for each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_sample = gdf.dissolve(by=\"SampleID\")[[\"geometry\"]]\n",
    "predictions_by_sample[\"prop_min\"] = (\n",
    "    gdf[\"Prediction\"]\n",
    "    .map(dict(Mineralized=1, Unmineralized=0))\n",
    "    .groupby(gdf[\"SampleID\"])\n",
    "    .mean()\n",
    ")\n",
    "# some samples might not have predictions, so we need to add nan here to avoid divide by zero/log(0) errors\n",
    "predictions_by_sample[\"counts\"] = (\n",
    "    gdf[\"Prediction\"].groupby(gdf[\"SampleID\"]).count().replace(0, np.nan)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have the locations for these samples, we can visualize all of this on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import plot_sample_predictions\n",
    "\n",
    "plot_sample_predictions(predictions_by_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can export the predictions for each individual grain, and also for each sample (here to GeoPackage, but there are a number of potential formats):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"../data/HMMA_spinel_with_predictions.gpkg\")\n",
    "predictions_by_sample.to_file(\"../data/HMMA_spinel_predictions_by_sample.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also send this to shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_sample.to_file(\n",
    "    \"../data/HMMA_spinel_predictions_by_sample.shp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "| [**Overview**](./00_overview.ipynb) | [**From Data Exploration to Machine Learning**](./01_EDA.ipynb) | [**Using `sklearn` Models**](./02_LoadModels.ipynb) | [**Making Predictions**](./03_Predictions.ipynb)|\n",
    "| -- | -- | -- | -- |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "im4nis-workshop-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
